# 01_PROJECT_BLUEPRINT.md

**Projeto:** Mind-to-Script (M2S) Engine
**Objetivo:** Pipeline de remasteriza√ß√£o de v√≠deo aulas usando IA Generativa Local.
**Refer√™ncia de Estrutura:** `00_PROJECT_STRUCTURE.md`

---

## 1. Vis√£o Macro do Pipeline

O projeto segue um fluxo linear (Waterfall). Cada fase √© bloqueante: a Fase 2 s√≥ come√ßa se a Fase 1 gerar seus arquivos com sucesso na pasta correta.

### üåä Fluxo de Dados
`V√≠deo Original` -> [Fase 1] -> `√Åudio` -> [Fase 2] -> `Texto` -> [Fase 3] -> `Roteiro` -> [Fase 4] -> `Assets` -> [Fase 5] -> `V√≠deo Final`

---

## 2. Detalhamento das Etapas

### üü¢ FASE 1: Ingest√£o e Extra√ß√£o
O objetivo √© preparar a mat√©ria-prima. O v√≠deo original √© pesado demais para ser processado diretamente por modelos de √°udio. Precisamos extrair o √°udio em um formato leve e compat√≠vel com IA.

* **Input:** Pasta `data/00_raw_input/`
* **Output:** Pasta `data/01_audio_extracted/`
* **Engine:** FFmpeg (via Python Wrapper).
* **Artefato Cr√≠tico:** Arquivo `.wav` (16kHz, mono).
* **üìÑ Documento de Especifica√ß√£o T√©cnica:** `02_SPEC_PHASE_01.md`

---

### üîµ FASE 2: Transcri√ß√£o Neural (ASR)
Aqui transformamos ondas sonoras em dados de texto brutos. Usaremos a NPU do Apple Silicon para fazer isso em alta velocidade.

* **Input:** Pasta `data/01_audio_extracted/`
* **Output:** Pasta `data/02_transcriptions/`
* **Engine:** `mlx-whisper` (Modelo: Large-v3).
* **Artefato Cr√≠tico:** Arquivo `.json` contendo texto completo + *word-level timestamps*.
* **üìÑ Documento de Especifica√ß√£o T√©cnica:** `03_SPEC_PHASE_02.md`

---

### üü£ FASE 3: A Mente (Estrutura√ß√£o LLM)
Esta √© a etapa mais complexa. Uma LLM (Llama 3.1) vai ler o texto "sujo" da fase anterior, entender o conte√∫do pedag√≥gico e reescrever um roteiro estruturado para v√≠deo, eliminando erros do professor original.

* **Input:** Pasta `data/02_transcriptions/`
* **Output:** Pasta `data/03_structured_scripts/`
* **Engine:** Ollama (Local) + Python (L√≥gica de Valida√ß√£o e Retry).
* **Artefato Cr√≠tico:** `script.json` (Validado estritamente por Schema Pydantic).
* **üìÑ Documento de Especifica√ß√£o T√©cnica:** `04_SPEC_PHASE_03.md`

---

### üü† FASE 4: F√°brica de Assets (TTS & GenAI)
Com o roteiro em m√£os, precisamos gerar os elementos multim√≠dia. O sistema vai clonar a voz do professor para ler o novo roteiro limpo e calcular exatamente quanto tempo cada slide deve durar.

* **Input:** Pasta `data/03_structured_scripts/`
* **Output:** Pasta `data/04_assets_generated/`
* **Engine:** GPT-SoVITS (√Åudio) + Librosa (An√°lise Temporal).
* **Artefato Cr√≠tico:**
    1.  Arquivos `.wav` para cada frase do roteiro.
    2.  `enriched_script.json` (O JSON original acrescido de `durationInFrames` para sincronia).
* **üìÑ Documento de Especifica√ß√£o T√©cnica:** `05_SPEC_PHASE_04.md`

---

### üî¥ FASE 5: Renderiza√ß√£o e Montagem
O "Load" do ETL. O motor de v√≠deo l√™ o roteiro enriquecido e monta os componentes visuais (React) em sincronia com os √°udios gerados.

* **Input:** Pasta `data/04_assets_generated/`
* **Output:** Pasta `data/05_final_output/`
* **Engine:** Remotion (Node.js/React) comandado via CLI.
* **Artefato Cr√≠tico:** Arquivo `.mp4` final (H.264 ou ProRes).
* **üìÑ Documento de Especifica√ß√£o T√©cnica:** `06_SPEC_PHASE_05.md`

---

## 3. Orquestra√ß√£o

O arquivo `src/main.py` n√£o conter√° l√≥gica de neg√≥cio. Ele ser√° apenas um gerenciador de estado que:
1.  Verifica se a Fase anterior gerou os arquivos necess√°rios.
2.  Chama o script da Fase atual.
3.  Para a execu√ß√£o imediatamente em caso de erro (Fail Fast).

---

## 4. Dicion√°rio de Conceitos e Decis√µes de Engenharia

Esta se√ß√£o explica o "Porqu√™" das especifica√ß√µes t√©cnicas, garantindo que a inten√ß√£o do projeto seja mantida em futuras manuten√ß√µes.

### 4.1. O Padr√£o de √Åudio (WAV 16kHz Mono)
Na **Fase 1**, n√£o estamos apenas "convertendo v√≠deo". Estamos criando o alimento ideal para a IA.
* **WAV (PCM s16le):** √â o √°udio "RAW" (cru). Diferente do MP3, que joga dados fora para comprimir (lossy), o WAV mant√©m a integridade matem√°tica da onda sonora. Isso evita que a IA "alucine" palavras devido a artefatos de compress√£o.
* **16kHz (Sample Rate):** A voz humana raramente passa de 8kHz. Pelo Teorema de Nyquist, 16kHz √© a frequ√™ncia perfeita para capturar a voz com clareza total sem desperdi√ßar processamento. O modelo Whisper √© nativo nessa frequ√™ncia.
* **Mono (1 Canal):** A IA n√£o precisa de "palco sonoro" (est√©reo). Remover o segundo canal corta o tamanho do arquivo pela metade e dobra a velocidade de ingest√£o na NPU.

### 4.2. A Transcri√ß√£o Temporal (Time-Aligned Data)
Na **Fase 2**, o objetivo n√£o √© apenas o texto. O valor real s√£o os **Timestamps**.
* O JSON gerado atua como um mapa: *"A palavra X foi dita exatamente no milissegundo Y"*.
* Sem essa precis√£o temporal (garantida pela flag `word_timestamps=True` no MLX), seria imposs√≠vel sincronizar o v√≠deo final na Fase 5.

### 4.3. O "Diretor" vs. O "Editor" (LLM vs. Code)
* **Fase 3 (LLM):** Atua como o **Roteirista/Editor**. Ele toma decis√µes criativas e subjetivas (limpar o texto, decidir o que √© um slide de t√≠tulo e o que √© c√≥digo). √â probabil√≠stico.
* **Fase 5 (Remotion):** Atua como a **Equipe de Filmagem**. √â determin√≠stico. Ele n√£o "pensa", ele apenas executa cegamente as ordens dadas pelo JSON. Se o JSON disser "dure 50 frames", ele durar√° exatos 50 frames.

### 4.4. A Ponte Cr√≠tica (Fase 4 - Assets)
Esta √© a etapa mais frequentemente negligenciada em pipelines de v√≠deo.
* Como o v√≠deo √© gerado via c√≥digo (Fase 5), ele n√£o sabe "ouvir" quando o √°udio acaba.
* A **Fase 4** √© obrigat√≥ria para calcular matematicamente a dura√ß√£o (`durationInFrames = segundos * 30fps`). Ela transforma a *dura√ß√£o do som* em *espa√ßo na timeline de v√≠deo*.